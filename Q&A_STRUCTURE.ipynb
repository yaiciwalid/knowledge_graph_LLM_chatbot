{"cells":[{"cell_type":"markdown","metadata":{"id":"uhYHVGdwrUNp"},"source":["## Installation"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":38394,"status":"ok","timestamp":1709650790879,"user":{"displayName":"WALID YAICI","userId":"13150495527287772964"},"user_tz":-60},"id":"mcBjnXthnz_j","outputId":"c76005b9-b203-41b6-96d0-645239751809"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting neo4j\n","  Downloading neo4j-5.18.0.tar.gz (198 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/198.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.9/198.0 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m198.0/198.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Collecting openai\n","  Downloading openai-1.13.3-py3-none-any.whl (227 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.4/227.4 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting langchain\n","  Downloading langchain-0.1.11-py3-none-any.whl (807 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m807.5/807.5 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tiktoken\n","  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from neo4j) (2023.4)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n","Collecting httpx<1,>=0.23.0 (from openai)\n","  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.6.3)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n","Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n","Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.10.0)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.27)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.3)\n","Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n","Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n","  Downloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n","Collecting jsonpatch<2.0,>=1.33 (from langchain)\n","  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n","Collecting langchain-community<0.1,>=0.0.25 (from langchain)\n","  Downloading langchain_community-0.0.25-py3-none-any.whl (1.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting langchain-core<0.2,>=0.1.29 (from langchain)\n","  Downloading langchain_core-0.1.29-py3-none-any.whl (252 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m252.6/252.6 kB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting langchain-text-splitters<0.1,>=0.0.1 (from langchain)\n","  Downloading langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\n","Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n","  Downloading langsmith-0.1.19-py3-none-any.whl (65 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.7/65.7 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n","Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n","Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.12.25)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n","Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n","  Downloading marshmallow-3.21.1-py3-none-any.whl (49 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n","  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n","Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n","  Downloading httpcore-1.0.4-py3-none-any.whl (77 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n","  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n","  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n","Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.29->langchain) (23.2)\n","Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n","  Downloading orjson-3.9.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.5/138.5 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n","Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.16.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n","Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n","  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n","Building wheels for collected packages: neo4j\n","  Building wheel for neo4j (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for neo4j: filename=neo4j-5.18.0-py3-none-any.whl size=273862 sha256=f73e690130f6aaad5ed613488caa5c737352d69db0d3a462efd5e6634f97ac4a\n","  Stored in directory: /root/.cache/pip/wheels/e7/e1/a0/dd7c19192f5383ff57d02a6c126cbfe4b7b2ae82f70c6994ce\n","Successfully built neo4j\n","Installing collected packages: orjson, neo4j, mypy-extensions, marshmallow, jsonpointer, h11, typing-inspect, tiktoken, jsonpatch, httpcore, langsmith, httpx, dataclasses-json, openai, langchain-core, langchain-text-splitters, langchain-community, langchain\n","Successfully installed dataclasses-json-0.6.4 h11-0.14.0 httpcore-1.0.4 httpx-0.27.0 jsonpatch-1.33 jsonpointer-2.4 langchain-0.1.11 langchain-community-0.0.25 langchain-core-0.1.29 langchain-text-splitters-0.0.1 langsmith-0.1.19 marshmallow-3.21.1 mypy-extensions-1.0.0 neo4j-5.18.0 openai-1.13.3 orjson-3.9.15 tiktoken-0.6.0 typing-inspect-0.9.0\n"]}],"source":["!pip install neo4j openai langchain tiktoken"]},{"cell_type":"markdown","metadata":{"id":"2B0YRcsarW0G"},"source":["## Connexion à la BD"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"vGH1qAyQn2jg"},"outputs":[],"source":["from langchain.graphs import Neo4jGraph\n","\n","url = \"\"\n","username =\"\"\n","password = \"\"\n","graph = Neo4jGraph(\n","    url=url,\n","    username=username,\n","    password=password\n",")"]},{"cell_type":"markdown","metadata":{"id":"zs-z4aHKWCvH"},"source":["## FONCTIONS"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"BDrG52WmWCYc"},"outputs":[],"source":["import os\n","from langchain.vectorstores.neo4j_vector import Neo4jVector\n","from langchain.embeddings.openai import OpenAIEmbeddings\n","import openai\n","import os\n","import re\n","from openai import OpenAI"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"9N6-Y4mE91IO"},"outputs":[],"source":["def schema_extraction(graph):\n","  schema_visualisation = graph.query(\"call db.schema.visualization\")\n","  rel_properties = graph.query(\"call db.schema.relTypeProperties\")\n","  node_properties = graph.query(\"call db.schema.nodeTypeProperties\")\n","\n","\n","\n","  assistant = \"Voici le schéma du graphe: \" + str(schema_visualisation) + \"Voici les propriété des différentes relations: \" + str(rel_properties) + \"Voici les propriétés des différents noeuds :\" + str(node_properties)\n","  return schema_visualisation, rel_properties, node_properties\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"mepA6L3H_LIi"},"outputs":[],"source":["def questionAnswering(question, graph, client):\n","  ##EXTRACTION SCHEMA DU GRAPH\n","  schema_visualisation, rel_properties, node_properties = schema_extraction(graph)\n","  ##GENERATION DE LA REQUETE CYPHER\n","  query_result = \"\"\n","  assistant = \"Here is the graph schema: \" + str(schema_visualisation) + \"\\n Here is the properties of the relations of the graph: \" + str(rel_properties) + \"\\n Here is the properties of the nodes of the graph:\" + str(node_properties)\n","\n","  prompt_template = \"\"\"\n","    give me a cypher Query to response to this:\n","    Question: {}\n","    \"\"\".format(question)\n","  messages = [ {\"role\": \"system\", \"content\": \"You are an expert in generating Cypher Query\"},\n","            {\"role\": \"user\", \"content\": prompt_template},\n","            {\"role\": \"assistant\", \"content\": assistant}\n","            ]\n","\n","  response = client.chat.completions.create(\n","    model=\"gpt-3.5-turbo\",\n","    messages=messages,\n","    temperature=0\n","  )\n","  print(response.choices[0].message.content)\n","\n","  ##EXTRACTION DE LA REQUETE CYPHER DE LA REPONSE DE GPT\n","  contenu_entre_backticks = re.findall(r\"```(.*?)```\", str(response.choices[0].message.content), re.DOTALL)\n","  if contenu_entre_backticks:\n","    for i, contenu in enumerate(contenu_entre_backticks, start=1):\n","        print(f\"Contenu entre les triple backticks #{i}:\")\n","\n","        contenu = contenu.replace(\"<-\", \"-\").replace(\"->\", \"-\")\n","        print(contenu)\n","        query_result = query_result + str(graph.query(contenu))\n","  else:\n","    contenu = response.choices[0].message.content.replace(\"<-\", \"-\").replace(\"->\", \"-\")\n","    query_result =  str(graph.query(contenu))\n","\n","  ##GENERATION DE LA REPONSE A LA QUESTION\n","  assistant = \"This is the set of facts for the result of the question: \\n\" + query_result\n","  print(assistant)\n","  #question2 = \"Using a Knowledge Graph, We extract this information:\\n\"+str(query_result)+\".Using only these facts, responds to this question:\"+question+ \"the facts may contain multiple responses.\"\n","  question2 = \"Generate a response to this question, using the given set of facts \" + question\n","  print(question2)\n","  messages =  [{\"role\" : \"system\", \"content\" : \"You are an expert in Answering generation using ONLY the given set of facts.\"},\n","              {\"role\": \"user\", \"content\": question2 },\n","              {\"role\": \"assistant\", \"content\": assistant}\n","\n","              ]\n","  response = client.chat.completions.create(\n","      model=\"gpt-3.5-turbo\",\n","      messages=messages,\n","      temperature=0\n","  )\n","  return (\"La réponse à la question est: \" + response.choices[0].message.content)"]},{"cell_type":"markdown","metadata":{"id":"68mpievQBDPZ"},"source":["## TEST"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"X62XF-NnAUVB"},"outputs":[],"source":["question1 = \"give me the set of persons who wrote and produced the same movie.\"\n","question2 = \"What are the movies in which Zendaya has appeared?\"\n","question3 = \"tell me about spiderman, and the cast of the film far from home\"\n","question4 = \"Give me the movies that have the same production company\"\n","question5 = \"How many actors played in the movie Don't Look Up\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26100,"status":"ok","timestamp":1709632089720,"user":{"displayName":"Maziz Yassine","userId":"07023992471159053402"},"user_tz":-60},"id":"6Q8omRcr_y5s","outputId":"80c75ef7-4092-44c5-ae2a-7c7cb56678d0"},"outputs":[{"name":"stdout","output_type":"stream","text":["To respond to the question \"tell me about Spiderman, and the cast of the film Far From Home\" using Cypher Query, you can use the following query:\n","\n","```cypher\n","MATCH (m:Movie)-[:Cast]->(p:Person)\n","WHERE m.title CONTAINS 'Spiderman' OR m.title CONTAINS 'Far From Home'\n","RETURN m.title AS Movie, COLLECT(p.name) AS Cast\n","```\n","\n","This query will match all movies related to Spiderman or Far From Home and retrieve the movie title along with the cast members.\n","Contenu entre les triple backticks #1:\n","cypher\n","MATCH (m:Movie)-[:Cast]-(p:Person)\n","WHERE m.title CONTAINS 'Spiderman' OR m.title CONTAINS 'Far From Home'\n","RETURN m.title AS Movie, COLLECT(p.name) AS Cast\n","\n","This is the set of facts for the result of the question: \n","[{'Movie': 'Spider-Man: Far From Home', 'Cast': ['Zendaya', 'Tom Holland', 'Samuel L. Jackson', 'Cobie Smulders', 'Jon Favreau', 'J. B. Smoove', 'Jacob Batalon', 'Martin Starr', 'Tony Revolori', 'Marisa Tomei', 'Jake Gyllenhaal']}]\n","Generate a response to this question, using the given set of facts tell me about spiderman, and the cast of the film far from home\n","La réponse à la question est: In the film \"Spider-Man: Far From Home,\" the cast includes Zendaya, Tom Holland, Samuel L. Jackson, Cobie Smulders, Jon Favreau, J. B. Smoove, Jacob Batalon, Martin Starr, Tony Revolori, Marisa Tomei, and Jake Gyllenhaal.\n"]}],"source":["\n","\n","os.environ['OPENAI_API_KEY'] = \"\"\n","\n","client = OpenAI()\n","\n","\n","answer = questionAnswering(question3, graph, client)\n","print(answer)"]}],"metadata":{"colab":{"collapsed_sections":["2B0YRcsarW0G"],"name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
