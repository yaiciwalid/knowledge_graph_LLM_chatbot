{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import wikipediaapi\n",
    "from graph_construct import wiki_spacy_extract_chunk\n",
    "from script_neo4j import kw_graph_construct\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "film_list = [\"Dune: Part Two\",\"Spider-Man: Far From Home\",\"Uncharted (film)\",\"The Great Gatsby (2013 film)\",\"Don't Look Up\",\"Inception\",\"Harry Potter and the Goblet of Fire (film)\",\"Harry Potter and the Philosopher's Stone (film)\",\"Oppenheimer (film)\",\"Interstellar (film)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wiki_content(page_title):\n",
    "  user_agent = \"My Wikipedia Scraper (contact@example.com)\"\n",
    "\n",
    "  wiki_wiki = wikipediaapi.Wikipedia(user_agent=user_agent)\n",
    "\n",
    "  page = wiki_wiki.page(page_title)\n",
    "\n",
    "  if page.exists():\n",
    "      return page.text\n",
    "  else:\n",
    "      return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "films_content = []\n",
    "for film in film_list:\n",
    "  films_content.append(get_wiki_content(film))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nettoyer_chaine(chaine):\n",
    "    # Utilisation d'une expression régulière pour ne garder que les caractères alphanumériques et les espaces\n",
    "    chaine_propre = re.sub(r'[^a-zA-Z0-9\\s]', '', chaine)\n",
    "    # Supprimer les doubles espaces\n",
    "    chaine_propre = re.sub(r'\\s+', ' ', chaine_propre)\n",
    "    # Retirer les espaces en début et fin de chaîne\n",
    "    chaine_propre = chaine_propre.strip()\n",
    "    return chaine_propre\n",
    "\n",
    "dataset = {}\n",
    "dataset['title_chunks'] = []\n",
    "\n",
    "for i, contenu in enumerate(films_content):\n",
    "  chunks = contenu.split('\\n\\n')\n",
    "  title = film_list[i]\n",
    "  for chunk in chunks:\n",
    "    chunk = nettoyer_chaine(chunk)\n",
    "    chunk = chunk.encode('utf-8').decode('utf-8')\n",
    "    dataset['title_chunks'].append((title, chunk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 192/192 [00:16<00:00, 11.76it/s]\n"
     ]
    }
   ],
   "source": [
    "test_docs = wiki_spacy_extract_chunk(dataset)\n",
    "with open('chunk.json', 'w') as file:\n",
    "    json.dump(test_docs, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path to your JSON file\n",
    "json_file_path = \"./chunk.json\"\n",
    "# Read the JSON file and load its content into a Python dictionary\n",
    "with open(json_file_path, \"r\") as json_file:\n",
    "    data_dictionary = json.load(json_file)\n",
    "kw_graph_construct(\"script.txt\", data_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from neo4j import GraphDatabase\n",
    "path = './script.txt'\n",
    "uri = \"\"\n",
    "user = \"\"\n",
    "password = \"\"\n",
    "driver = GraphDatabase.driver(uri, auth=(user, password))\n",
    "with driver.session() as session:\n",
    "  with open(path, \"r\") as file:\n",
    "      contenu = file.read()\n",
    "      requetes = contenu.split('\\n')\n",
    "      for i in tqdm(range(len(requetes))):\n",
    "        session.run(requetes[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
